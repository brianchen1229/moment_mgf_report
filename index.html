<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Comparing Numerical Methods for Moment Calculation in the Bivariate Normal MGF</title>
  <meta name="description" content="Compare numerical methods and step sizes using the bivariate normal MGF to estimate moments and correlation." />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <style>
    body {font-family: Inter, Arial, sans-serif; margin:0; background:#fff; color:#222; line-height:1.6}
    .container {max-width:900px; margin:0 auto; padding:40px 20px}
    .card {background:#f9f9f9; border:1px solid #e0e0e0; border-radius:12px; padding:24px; margin:20px 0}
    .btn {display:inline-block; padding:10px 18px; background:#1976d2; color:#fff; border-radius:8px; text-decoration:none}
  </style>
</head>
<body>
  <div class="container">
    <header style="text-align:center; margin-bottom:32px;">
      <h1>Numerical Differentiation via the Bivariate Normal MGF</h1>
      <p class="lead">A brief English version of this project. The full report (in Mandarin) is available below. </p>
      <a class="btn" href="moment.pdf" download>ðŸ“„ Download Full Report (PDF)</a>
    </header>

    <section class="card">
      <h2>Abstract</h2>
      <p>
        Numerical differentiation on computers is subject to both truncation and rounding errors; 
        therefore, reducing the step size \(h\) does not necessarily decrease the total error. 
        This study explores this trade-off using the moment-generating function (MGF) of a bivariate 
        normal distribution as a test function and compares two numerical methods: 
        the three-point and five-point formulas. Overall, accurate results are obtained when 
        \(h\) lies between \(10^{-7}\) and \(10^{-3}\); beyond this range, both formulas become 
        unstable, with the five-point differentiation formula exhibiting instability more readily 
        than the three-point formula.
      </p>
    </section>

    <section class="card">
      <h2>Motivation</h2>
      <p>
        When performing numerical differentiation on a computer, significant errors can arise when dealing with extremely large or small values due to the limitations of floating-point arithmetic. Therefore, unlike in calculus, where the derivative is defined as
      </p>
      <p style="text-align:center; margin: 12px 0;">
        \[
          f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h},
        \]
      </p>
      <p>
        decreasing the step size \(h\) indefinitely does not necessarily lead to more accurate results. In fact, taking \(h\) too small can increase rounding errors and cause numerical instability.
      </p>
      <p>
        This project investigates how different step sizes affect the accuracy of numerical differentiation by comparing computed results with true values. The goal is to identify the range of \(h\) that minimizes total error. Additionally, the study compares several finite-difference formulas, specifically the two-point, three-point, and five-point methods, to determine which provides the most reliable approximation under various step sizes.
      </p>
    </section>

    <section class="card">
      <h2>Experimental Setup</h2>
      <p>
        We consider a bivariate normal distribution \((X,Y)\sim BN(\mu_X,\mu_Y,\sigma_X^2,\sigma_Y^2,\rho)\)
        with parameters \(\mu_X=5\), \(\mu_Y=4\), \(\sigma_X^2=16\), \(\sigma_Y^2=25\), and \(\rho=0.5\).
        The corresponding moment-generating function (MGF) is:
      </p>
    
      <p style="text-align:center; margin: 12px 0;">
        \[
          M(t_1,t_2) = \exp\!\Bigg[
            5t_1 + 4t_2 +
            \frac{1}{2}\big(16t_1^2 + 2\times 0.5\times 4\times 5\, t_1 t_2 + 25t_2^2\big)
          \Bigg],\quad t_1,t_2\in\mathbb{R}.
        \]
      </p>
    
      <p>
        We use finite-difference formulas to approximate the derivatives of the MGF
        around \((t_1,t_2)=(0,0)\) in order to estimate the moments such as \(E[X]\) and \(E[X^2]\).
        The following formulas are applied.
      </p>
    
      <h3>First Derivative (for \(E[X]\))</h3>

      <p><em>Five-point (central difference):</em></p>
      <p style="text-align:center; margin: 8px 0;">
        \[ E(X) \approx \frac{M(0-2h,0)-8M(0-h,0)+8M(0+h,0)-M(0+2h,0)}{12h}. \]

        \[ E(Y) \approx \frac{M(0,0-2h)-8M(0,0-h)+8M(0,0+h)-M(0,0+2h)}{12h}. \]
      </p>
      
      <h3>Second Derivative (for \(E[X^2]\))</h3>
    
      <p><em>Three-point formula:</em></p>
      <p style="text-align:center; margin: 8px 0;">
        \[ E(X^2) \approx \frac{M(0-h,0)-2M(0,0)+M(0+h,0)}{h^2}. \]

        \[ E(Y^2) \approx \frac{M(0,0-h)-2M(0,0)+M(0,0+h)}{h^2}. \]
      </p>
    
      <p><em>Five-point formula:</em></p>
      <p style="text-align:center; margin: 8px 0;">
        \[ E(X^2) \approx \frac{-M(0-2h,0)+16M(0-h,0)-30M(0,0)+16M(0+h,0)-M(0+2h,0)}{h^2}. \]

        \[ E(Y^2) \approx \frac{-M(0,0-2h)+16M(0,0-h)-30M(0,0)+16M(0,0+h)-M(0,0+2h)}{h^2}. \]
      </p>

    <h3>Partial Derivative (for \(E[XY]\))</h3>

      <p>
        To approximate the mixed moment \(E[XY]\), we compute the mixed partial
        derivative \(\frac{\partial^2 M}{\partial t_1\,\partial t_2}\big|_{(0,0)}\)
        using finite-difference formulas. Two commonly used schemes are listed below.
      </p>
      
      <p><em>Formula 1:</em></p>
      <p style="text-align:center; margin: 8px 0;">
        \[
          E(XY) \approx
          \frac{
            M(h,0+k) - M(h,0) - M(0,k) + 2M(0,0)
            - M(-h,0) - M(0,-k) + M(-h,-k)
          }{2hk}.
        \]
      </p>
      
      <p><em>Formula 2:</em></p>
      <p style="text-align:center; margin: 8px 0;">
        \[
          E(XY) \approx
          \frac{
            M(h, k) - M(h, -k)
            - M(-h, k) + M(-h, -k)
          }{4hk}.
        \]
      </p>

      <p>
      When the step size \(h\) is sufficiently small, the finite-difference
      formulas above provide accurate approximations of \(E(X^2)\) and \(E(Y^2)\).
      Using these approximations, the variances of \(X\) and \(Y\) can be computed via
      </p>
      
      <p style="text-align:center; margin: 8px 0;">
        \[
          \mathrm{Var}(X) = E(X^2) - (E(X))^2,
          \qquad
          \mathrm{Var}(Y) = E(Y^2) - (E(Y))^2.
        \]
      </p>
      
      <p>
        Similarly, when the step sizes \(h\) and \(k\) are small enough, the mixed
        finite-difference formulas yield a reliable approximation of \(E(XY)\).
      </p>
      
      <p style="text-align:center; margin: 8px 0;">
        \[
          \rho =
          \frac{E(XY) - E(X)E(Y)}
               {\sqrt{\mathrm{Var}(X)\,\mathrm{Var}(Y)}}.
        \]
      </p>
      
      <p>
        This allows us to compute the correlation coefficient between \(X\) and \(Y\).
      </p>



      
    <footer style="text-align:center; margin-top:40px;">
      <p>Â© 2025 Brian Chen â€¢ <a href="moment.pdf">PDF</a></p>
    </footer>
  </div>
</body>
</html>
